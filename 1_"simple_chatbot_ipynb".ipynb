{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1.\"simple_chatbot.ipynb\"",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kkattt51/ArtInt/blob/main/1_%22simple_chatbot_ipynb%22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4i5b0ZSl7v8",
        "outputId": "aaef7a06-2695-492f-d7ca-ee5c2e253184"
      },
      "source": [
        "!pip install nltk\n",
        "!pip install pymorphy2\n",
        "!pip install pymorphy2-dicts"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n",
            "Collecting pymorphy2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/57/b2ff2fae3376d4f3c697b9886b64a54b476e1a332c67eee9f88e7f1ae8c9/pymorphy2-0.9.1-py3-none-any.whl (55kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 4.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (0.6.2)\n",
            "Collecting dawg-python>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
            "Collecting pymorphy2-dicts-ru<3.0,>=2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/79/bea0021eeb7eeefde22ef9e96badf174068a2dd20264b9a378f2be1cdd9e/pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2MB)\n",
            "\u001b[K     |████████████████████████████████| 8.2MB 13.3MB/s \n",
            "\u001b[?25hInstalling collected packages: dawg-python, pymorphy2-dicts-ru, pymorphy2\n",
            "Successfully installed dawg-python-0.7.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n",
            "Collecting pymorphy2-dicts\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/51/2465fd4f72328ab50877b54777764d928da8cb15b74e2680fc1bd8cb3173/pymorphy2_dicts-2.4.393442.3710985-py2.py3-none-any.whl (7.1MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1MB 5.8MB/s \n",
            "\u001b[?25hInstalling collected packages: pymorphy2-dicts\n",
            "Successfully installed pymorphy2-dicts-2.4.393442.3710985\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVvW_X5qmfgR"
      },
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "import random\n",
        "import string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpNHG0-2mfwV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "outputId": "fd47e016-2681-4c6a-88df-b699b59b0420"
      },
      "source": [
        "with open('article.txt','r',errors = 'ignore') as f:\n",
        "  raw=f.read()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-6c2339cb0e3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'article.txt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mraw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'article.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzA8Z1ylnWFl"
      },
      "source": [
        "raw = raw.lower() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Aa2mJfLnhMC",
        "outputId": "a99d1da9-1075-4a2b-824e-5b9d4c62562c"
      },
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYuMLvt0nmOW"
      },
      "source": [
        "sent_tokens = nltk.sent_tokenize(raw)\n",
        "word_tokens = nltk.word_tokenize(raw)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjDfboiLnqpl",
        "outputId": "f2f0f61f-e04f-4b60-b1c8-29b9f65aba46"
      },
      "source": [
        "sent_tokens[:300]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['цель машинного обучения — предсказать результат по входным данным.',\n",
              " 'чем разнообразнее входные данные, тем проще машине найти закономерности и тем точнее результат.',\n",
              " 'итак, если мы хотим обучить машину, нам нужны три вещи:\\n\\nданные хотим определять спам — нужны примеры спам-писем, предсказывать курс акций — нужна история цен, узнать интересы пользователя — нужны его лайки или посты.',\n",
              " 'данных нужно как можно больше.',\n",
              " 'десятки тысяч примеров — это самый злой минимум для отчаянных.',\n",
              " 'данные собирают как могут.',\n",
              " 'кто-то вручную — получается дольше, меньше, зато без ошибок.',\n",
              " 'кто-то автоматически — просто сливает машине всё, что нашлось, и верит в лучшее.',\n",
              " 'самые хитрые, типа гугла, используют своих же пользователей для бесплатной разметки.',\n",
              " 'вспомните recaptcha, которая иногда требует «найти на фотографии все дорожные знаки» — это оно и есть.',\n",
              " 'за хорошими наборами данных (датасетами) идёт большая охота.',\n",
              " 'крупные компании, бывает, раскрывают свои алгоритмы, но датасеты — крайне редко.',\n",
              " 'признаки мы называем их фичами (features), так что ненавистникам англицизмов придётся страдать.',\n",
              " 'фичи, свойства, характеристики, признаки — ими могут быть пробег автомобиля, пол пользователя, цена акций, даже счетчик частоты появления слова в тексте может быть фичей.',\n",
              " 'машина должна знать, на что ей конкретно смотреть.',\n",
              " 'хорошо, когда данные просто лежат в табличках — названия их колонок и есть фичи.',\n",
              " 'а если у нас сто гигабайт картинок с котами?',\n",
              " 'когда признаков много, модель работает медленно и неэффективно.',\n",
              " 'зачастую отбор правильных фич занимает больше времени, чем всё остальное обучение.',\n",
              " 'но бывают и обратные ситуации, когда кожаный мешок сам решает отобрать только «правильные» на его взгляд признаки и вносит в модель субъективность — она начинает дико врать.',\n",
              " 'алгоритм одну задачу можно решить разными методами примерно всегда.',\n",
              " 'от выбора метода зависит точность, скорость работы и размер готовой модели.',\n",
              " 'но есть один нюанс: если данные говно, даже самый лучший алгоритм не поможет.',\n",
              " 'не зацикливайтесь на процентах, лучше соберите побольше данных.однажды в одном хипстерском издании я видел статью под заголовком «заменят ли нейросети машинное обучение».',\n",
              " 'пиарщики в своих пресс-релизах обзывают «искусственным интеллектом» любую линейную регрессию, с которой уже дети во дворе играют.',\n",
              " 'объясняю разницу на картинке, раз и навсегда.искусственный интеллект — название всей области, как биология или химия.машинное обучение — это раздел искусственного интеллекта.',\n",
              " 'важный, но не единственный.нейросети — один из видов машинного обучения.',\n",
              " 'популярный, но есть и другие, не хуже.глубокое обучение — архитектура нейросетей, один из подходов к их построению и обучению.',\n",
              " 'на практике сегодня мало кто отличает, где глубокие нейросети, а где не очень.',\n",
              " 'говорят название конкретной сети и всё.',\n",
              " 'сравнивать можно только вещи одного уровня, иначе получается полный буллщит типа «что лучше: машина или колесо?» не отождествляйте термины без причины, чтобы не выглядеть дурачком.',\n",
              " 'вот что машины сегодня умеют, а что не под силу даже самым обученным.',\n",
              " 'машина может\\tмашина не может\\nпредсказывать\\tсоздавать новое\\nзапоминать\\tрезко поумнеть\\nвоспроизводить\\tвыйти за рамки задачи\\nвыбирать лучшее\\tубить всех людей\\n 1думаю потом нарисовать полноценную настенную карту со стрелочками и объяснениями, что где используется, если статья зайдёт.',\n",
              " 'и да.',\n",
              " 'классифицировать алгоритмы можно десятком способов.',\n",
              " 'я выбрал этот, потому что он мне кажется самым удобным для повествования.',\n",
              " 'надо понимать, что не бывает так, чтобы задачу решал только один метод.',\n",
              " 'я буду упоминать известные примеры применений, но держите в уме, что «сын маминой подруги» всё это может решить нейросетями.',\n",
              " 'начну с базового обзора.',\n",
              " 'сегодня в машинном обучении есть всего четыре основных направления.первые алгоритмы пришли к нам из чистой статистики еще в 1950-х.',\n",
              " 'они решали формальные задачи — искали закономерности в циферках, оценивали близость точек в пространстве и вычисляли направления.',\n",
              " 'сегодня на классических алгоритмах держится добрая половина интернета.',\n",
              " 'когда вы встречаете блок «рекомендованные статьи» на сайте, или банк блокирует все ваши деньги на карточке после первой же покупки кофе за границей — это почти всегда дело рук одного из этих алгоритмов.',\n",
              " 'да, крупные корпорации любят решать все проблемы нейросетями.',\n",
              " 'потому что лишние 2% точности для них легко конвертируются в дополнительные 2 миллиарда прибыли.',\n",
              " 'остальным же стоит включать голову.',\n",
              " 'когда задача решаема классическими методами, дешевле реализовать сколько-нибудь полезную для бизнеса систему на них, а потом думать об улучшениях.',\n",
              " 'а если вы не решили задачу, то не решить её на 2% лучше вам не особо поможет.',\n",
              " 'знаю несколько смешных историй, когда команда три месяца переписывала систему рекомендаций интернет-магазина на более точный алгоритм, и только потом понимала, что покупатели вообще ей не пользуются.',\n",
              " 'большая часть просто приходит из поисковиков.',\n",
              " 'при всей своей популярности, классические алгоритмы настолько просты, что их легко объяснить даже ребёнку.',\n",
              " 'сегодня они как основы арифметики — пригождаются постоянно, но некоторые всё равно стали их забывать.классическое обучение любят делить на две категории — с учителем и без.',\n",
              " 'часто можно встретить их английские наименования — supervised и unsupervised learning.',\n",
              " 'в первом случае у машины есть некий учитель, который говорит ей как правильно.',\n",
              " 'рассказывает, что на этой картинке кошка, а на этой собака.',\n",
              " 'то есть учитель уже заранее разделил (разметил) все данные на кошек и собак, а машина учится на конкретных примерах.',\n",
              " 'в обучении без учителя, машине просто вываливают кучу фотографий животных на стол и говорят «разберись, кто здесь на кого похож».',\n",
              " 'данные не размечены, у машины нет учителя, и она пытается сама найти любые закономерности.',\n",
              " 'об этих методах поговорим ниже.',\n",
              " 'очевидно, что с учителем машина обучится быстрее и точнее, потому в боевых задачах его используют намного чаще.',\n",
              " 'эти задачи делятся на два типа: классификация — предсказание категории объекта, и регрессия — предсказание места на числовой прямой.«разделяет объекты по заранее известному признаку.',\n",
              " 'носки по цветам, документы по языкам, музыку по жанрам»\\n\\nсегодня используют для:\\n\\nспам-фильтры\\nопределение языка\\nпоиск похожих документов\\nанализ тональности\\nраспознавание рукописных букв и цифр\\nопределение подозрительных транзакцийклассификация вещей — самая популярная задача во всём машинном обучении.',\n",
              " 'машина в ней как ребёнок, который учится раскладывать игрушки: роботов в один ящик, танки в другой.',\n",
              " 'опа, а если это робот-танк?',\n",
              " 'штош, время расплакаться и выпасть в ошибку.для классификации всегда нужен учитель — размеченные данные с признаками и категориями, которые машина будет учиться определять по этим признакам.',\n",
              " 'дальше классифицировать можно что угодно: пользователей по интересам — так делают алгоритмические ленты, статьи по языкам и тематикам — важно для поисковиков, музыку по жанрам — вспомните плейлисты спотифая и яндекс.музыки, даже письма в вашем почтовом ящике.раньше все спам-фильтры работали на алгоритме наивного байеса.',\n",
              " 'машина считала сколько раз слово «виагра» встречается в спаме, а сколько раз в нормальных письмах.',\n",
              " 'перемножала эти две вероятности по формуле байеса, складывала результаты всех слов и бац, всем лежать, у нас машинное обучение!позже спамеры научились обходить фильтр байеса, просто вставляя в конец письма много слов с «хорошими» рейтингами.',\n",
              " 'метод получил ироничное название отравление байеса, а фильтровать спам стали другими алгоритмами.',\n",
              " 'но метод навсегда остался в учебниках как самый простой, красивый и один из первых практически полезных.',\n",
              " 'возьмем другой пример полезной классификации.',\n",
              " 'вот берёте вы кредит в банке.',\n",
              " 'как банку удостовериться, вернёте вы его или нет?',\n",
              " 'точно никак, но у банка есть тысячи профилей других людей, которые уже брали кредит до вас.',\n",
              " 'там указан их возраст, образование, должность, уровень зарплаты и главное — кто из них вернул кредит, а с кем возникли проблемы.',\n",
              " 'да, все догадались, где здесь данные и какой надо предсказать результат.',\n",
              " 'обучим машину, найдём закономерности, получим ответ — вопрос не в этом.',\n",
              " 'проблема в том, что банк не может слепо доверять ответу машины, без объяснений.',\n",
              " 'вдруг сбой, злые хакеры или бухой админ решил скриптик исправить.для этой задачи придумали деревья решений.',\n",
              " 'машина автоматически разделяет все данные по вопросам, ответы на которые «да» или «нет».',\n",
              " 'вопросы могут быть не совсем адекватными с точки зрения человека, например «зарплата заёмщика больше, чем 25934 рубля?», но машина придумывает их так, чтобы на каждом шаге разбиение было самым точным.',\n",
              " 'так получается дерево вопросов.',\n",
              " 'чем выше уровень, тем более общий вопрос.',\n",
              " 'потом даже можно загнать их аналитикам, и они навыдумывают почему так.',\n",
              " 'деревья нашли свою нишу в областях с высокой ответственностью: диагностике, медицине, финансах.',\n",
              " 'два самых популярных алгоритма построения деревьев — cart и c4.5.',\n",
              " 'в чистом виде деревья сегодня используют редко, но вот их ансамбли (о которых будет ниже) лежат в основе крупных систем и зачастую уделывают даже нейросети.',\n",
              " 'например, когда вы задаете вопрос яндексу, именно толпа глупых деревьев бежит ранжировать вам результаты.',\n",
              " 'но самым популярным методом классической классификации заслуженно является метод опорных векторов (svm).',\n",
              " 'им классифицировали уже всё: виды растений, лица на фотографиях, документы по тематикам, даже странных playboy-моделей.',\n",
              " 'много лет он был главным ответом на вопрос «какой бы мне взять классификатор».',\n",
              " 'идея svm по своей сути проста — он ищет, как так провести две прямые между категориями, чтобы между ними образовался наибольший зазор.',\n",
              " 'на картинке видно нагляднее:у классификации есть полезная обратная сторона — поиск аномалий.',\n",
              " 'когда какой-то признак объекта сильно не вписывается в наши классы, мы ярко подсвечиваем его на экране.',\n",
              " 'сейчас так делают в медицине: компьютер подсвечивает врачу все подозрительные области мрт или выделяет отклонения в анализах.',\n",
              " 'на биржах таким же образом определяют нестандартных игроков, которые скорее всего являются инсайдерами.',\n",
              " 'научив компьютер «как правильно», мы автоматически получаем и обратный классификатор — как неправильно.',\n",
              " 'сегодня для классификации всё чаще используют нейросети, ведь по сути их для этого и изобрели.правило буравчика такое: сложнее данные — сложнее алгоритм.',\n",
              " 'для текста, цифр, табличек я бы начинал с классики.',\n",
              " 'там модели меньше, обучаются быстрее и работают понятнее.',\n",
              " 'для картинок, видео и другой непонятной бигдаты — сразу смотрел бы в сторону нейросетей.',\n",
              " 'лет пять назад еще можно было встретить классификатор лиц на svm, но сегодня под эту задачу сотня готовых сеток по интернету валяются, чо бы их не взять.',\n",
              " 'а вот спам-фильтры как на svm писали, так и не вижу смысла останавливаться.«нарисуй линию вдоль моих точек.',\n",
              " 'да, это машинное обучение»\\n\\nсегодня используют для:\\n\\nпрогноз стоимости ценных бумаг\\nанализ спроса, объема продаж\\nмедицинские диагнозы\\nлюбые зависимости числа от времени\\nпопулярные алгоритмы: линейная или полиномиальная регрессиярегрессия — та же классификация, только вместо категории мы предсказываем число.',\n",
              " 'стоимость автомобиля по его пробегу, количество пробок по времени суток, объем спроса на товар от роста компании и.т.д.',\n",
              " 'на регрессию идеально ложатся любые задачи, где есть зависимость от времени.',\n",
              " 'регрессию очень любят финансисты и аналитики, она встроена даже в excel.',\n",
              " 'внутри всё работает, опять же, банально: машина тупо пытается нарисовать линию, которая в среднем отражает зависимость.',\n",
              " 'правда, в отличии от человека с фломастером и вайтбордом, делает она это математически точно — считая среднее расстояние до каждой точки и пытаясь всем угодить.когда регрессия рисует прямую линию, её называют линейной, когда кривую — полиномиальной.',\n",
              " 'это два основных вида регрессии, дальше уже начинаются редкоземельные методы.',\n",
              " 'но так как в семье не без урода, есть логистическая регрессия, которая на самом деле не регрессия, а метод классификации, от чего у всех постоянно путаница.',\n",
              " 'не делайте так.',\n",
              " 'схожесть регрессии и классификации подтверждается еще и тем, что многие классификаторы, после небольшого тюнинга, превращаются в регрессоры.',\n",
              " 'например, мы можем не просто смотреть к какому классу принадлежит объект, а запоминать, насколько он близок — и вот, у нас регрессия.',\n",
              " 'для желающих понять это глубже, но тоже простыми словами, рекомендую цикл статей machine learning for humansобучение без учителя\\nобучение без учителя (unsupervised learning) было изобретено позже, аж в 90-е, и на практике используется реже.',\n",
              " 'но бывают задачи, где у нас просто нет выбора.',\n",
              " 'размеченные данные, как я сказал, дорогая редкость.',\n",
              " 'но что делать если я хочу, например, написать классификатор автобусов — идти на улицу руками фотографировать миллион сраных икарусов и подписывать где какой?',\n",
              " 'так и жизнь вся пройдёт, а у меня еще игры в стиме не пройдены.',\n",
              " 'когда нет разметки, есть надежда на капитализм, социальное расслоение и миллион китайцев из сервисов типа яндекс.толока, которые готовы делать для вас что угодно за пять центов.',\n",
              " 'так обычно и поступают на практике.',\n",
              " 'а вы думали где яндекс берёт все свои крутые датасеты?',\n",
              " 'либо, можно попробовать обучение без учителя.',\n",
              " 'хотя, честно говоря, из своей практики я не помню чтобы где-то оно сработало хорошо.',\n",
              " 'обучение без учителя, всё же, чаще используют как метод анализа данных, а не как основной алгоритм.',\n",
              " 'специальный кожаный мешок с дипломом мгу вбрасывает туда кучу мусора и наблюдает.',\n",
              " 'кластеры есть?',\n",
              " 'зависимости появились?',\n",
              " 'нет?',\n",
              " 'ну штош, продолжай, труд освобождает.',\n",
              " 'тыж хотел работать в датасаенсе.кластеризация«разделяет объекты по неизвестному признаку.',\n",
              " 'машина сама решает как лучше»\\n\\nсегодня используют для:\\n\\nсегментация рынка (типов покупателей, лояльности)\\nобъединение близких точек на карте\\nсжатие изображений\\nанализ и разметки новых данных\\nдетекторы аномального поведения\\nпопулярные алгоритмы: метод k-средних, mean-shift, dbscanкластеризация — это классификация, но без заранее известных классов.',\n",
              " 'она сама ищет похожие объекты и объединяет их в кластеры.',\n",
              " 'количество кластеров можно задать заранее или доверить это машине.',\n",
              " 'похожесть объектов машина определяет по тем признакам, которые мы ей разметили — у кого много схожих характеристик, тех давай в один класс.',\n",
              " 'отличный пример кластеризации — маркеры на картах в вебе.',\n",
              " 'когда вы ищете все крафтовые бары в москве, движку приходится группировать их в кружочки с циферкой, иначе браузер зависнет в потугах нарисовать миллион маркеров.',\n",
              " 'более сложные примеры кластеризации можно вспомнить в приложениях iphoto или google photos, которые находят лица людей на фотографиях и группируют их в альбомы.',\n",
              " 'приложение не знает как зовут ваших друзей, но может отличить их по характерным чертам лица.',\n",
              " 'типичная кластеризация.',\n",
              " 'правда для начала им приходится найти эти самые «характерные черты», а это уже только с учителем.',\n",
              " 'сжатие изображений — еще одна популярная проблема.',\n",
              " 'сохраняя картинку в png, вы можете установить палитру, скажем, в 32 цвета.',\n",
              " 'тогда кластеризация найдёт все «примерно красные» пиксели изображения, высчитает из них «средний красный по больнице» и заменит все красные на него.',\n",
              " 'меньше цветов — меньше файл.',\n",
              " 'проблема только, как быть с цветами типа cyan ◼︎ — вот он ближе к зеленому или синему?',\n",
              " 'тут нам поможет популярный алгоритм кластеризации — метод к-средних (k-means).',\n",
              " 'мы случайным образом бросаем на палитру цветов наши 32 точки, обзывая их центроидами.',\n",
              " 'все остальные точки относим к ближайшему центроиду от них — получаются как бы созвездия из самых близких цветов.',\n",
              " 'затем двигаем центроид в центр своего созвездия и повторяем пока центроиды не перестанут двигаться.',\n",
              " 'кластеры обнаружены, стабильны и их ровно 32 как и надо было.искать центроиды удобно и просто, но в реальных задачах кластеры могут быть совсем не круглой формы.',\n",
              " 'вот вы геолог, которому нужно найти на карте схожие по структуре горные породы — ваши кластеры не только будут вложены друг в друга, но вы ещё и не знаете сколько их вообще получится.',\n",
              " 'хитрым задачам — хитрые методы.',\n",
              " 'dbscan, например.',\n",
              " 'он сам находит скопления точек и строит вокруг кластеры.',\n",
              " 'его легко понять, если представить, что точки — это люди на площади.',\n",
              " 'находим трёх любых близко стоящих человека и говорим им взяться за руки.',\n",
              " 'затем они начинают брать за руку тех, до кого могут дотянуться.',\n",
              " 'так по цепочке, пока никто больше не сможет взять кого-то за руку — это и будет первый кластер.',\n",
              " 'повторяем, пока не поделим всех.',\n",
              " 'те, кому вообще некого брать за руку — это выбросы, аномалии.',\n",
              " 'в динамике выглядит довольно красиво:интересующимся кластеризацией рекомендую статью the 5 clustering algorithms data scientists need to know\\n\\nкак и классификация, кластеризация тоже может использоваться как детектор аномалий.',\n",
              " 'поведение пользователя после регистрации резко отличается от нормального?',\n",
              " 'заблокировать его и создать тикет саппорту, чтобы проверили бот это или нет.',\n",
              " 'при этом нам даже не надо знать, что есть «нормальное поведение» — мы просто выгружаем все действия пользователей в модель, и пусть машина сама разбирается кто тут нормальный.',\n",
              " 'работает такой подход, по сравнению с классификацией, не очень.',\n",
              " \"но за спрос не бьют, вдруг получится.уменьшение размерности (обобщение)«собирает конкретные признаки в абстракции более высокого уровня»\\n\\nсегодня используют для:\\n\\nрекомендательные системы (★)\\nкрасивые визуализации\\nопределение тематики и поиска похожих документов\\nанализ фейковых изображений\\nриск-менеджмент\\nпопулярные алгоритмы: метод главных компонент (pca), сингулярное разложение (svd), латентное размещение дирихле (lda), латентно-семантический анализ (lsa, plsa, glsa), t-sne (для визуализации)изначально это были методы хардкорных data scientist'ов, которым сгружали две фуры цифр и говорили найти там что-нибудь интересное.\",\n",
              " 'когда просто строить графики в экселе уже не помогало, они придумали напрячь машины искать закономерности вместо них.',\n",
              " 'так у них появились методы, которые назвали dimension reduction или feature learning.для нас практическая польза их методов в том, что мы можем объединить несколько признаков в один и получить абстракцию.',\n",
              " 'например, собаки с треугольными ушами, длинными носами и большими хвостами соединяются в полезную абстракцию «овчарки».',\n",
              " 'да, мы теряем информацию о конкретных овчарках, но новая абстракция всяко полезнее этих лишних деталей.',\n",
              " 'плюс, обучение на меньшем количестве размерностей идёт сильно быстрее.',\n",
              " 'инструмент на удивление хорошо подошел для определения тематик текстов (topic modelling).',\n",
              " 'мы смогли абстрагироваться от конкретных слов до уровня смыслов даже без привлечения учителя со списком категорий.',\n",
              " 'алгоритм назвали латентно-семантический анализ (lsa), и его идея была в том, что частота появления слова в тексте зависит от его тематики: в научных статьях больше технических терминов, в новостях о политике — имён политиков.',\n",
              " 'да, мы могли бы просто взять все слова из статей и кластеризовать, как мы делали с ларьками выше, но тогда мы бы потеряли все полезные связи между словами, например, что батарейка и аккумулятор, означают одно и то же в разных документах.',\n",
              " 'точность такой системы — полное дно, даже не пытайтесь.',\n",
              " 'нужно как-то объединить слова и документы в один признак, чтобы не терять эти скрытые (латентные) связи.',\n",
              " 'отсюда и появилось название метода.',\n",
              " 'оказалось, что сингулярное разложение (svd) легко справляется с этой задачей, выявляя для нас полезные тематические кластеры из слов, которые встречаются вместе.для понимания рекомендую статью как уменьшить количество измерений и извлечь из этого пользу, а практическое применение хорошо описано в статье алгоритм lsa для поиска похожих документов.',\n",
              " 'другое мега-популярное применение метода уменьшения размерности нашли в рекомендательных системах и коллаборативной фильтрации (у меня был пост про их виды).',\n",
              " 'оказалось, если абстрагировать ими оценки пользователей фильмам, получается неплохая система рекомендаций кино, музыки, игр и чего угодно вообще.',\n",
              " 'полученная абстракция будет с трудом понимаема мозгом, но когда исследователи начали пристально рассматривать новые признаки, они обнаружили, что какие-то из них явно коррелируют с возрастом пользователя (дети чаще играли в майнкрафт и смотрели мультфильмы), другие с определёнными жанрами кино, а третьи вообще с синдромом поиска глубокого смысла.',\n",
              " 'машина, не знавшая ничего кроме оценок пользователей, смогла добраться до таких высоких материй, даже не понимая их.',\n",
              " 'достойно.',\n",
              " 'дальше можно проводить соцопросы и писать дипломные работы о том, почему бородатые мужики любят дегенеративные мультики.',\n",
              " 'на эту тему есть неплохая лекция яндекса — как работают рекомендательные системы\\n\\nпоиск правил (ассоциация)\\n«ищет закономерности в потоке заказов»\\n\\nсегодня используют для:\\n\\nпрогноз акций и распродаж\\nанализ товаров, покупаемых вместе\\nрасстановка товаров на полках\\nанализ паттернов поведения на веб-сайтах\\nпопулярные алгоритмы: apriori, euclat, fp-growthсюда входят все методы анализа продуктовых корзин, стратегий маркетинга и других последовательностей.',\n",
              " 'предположим, покупатель берёт в дальнем углу магазина пиво и идёт на кассу.',\n",
              " 'стоит ли ставить на его пути орешки?',\n",
              " 'часто ли люди берут их вместе?',\n",
              " 'орешки с пивом, наверное да, но какие ещё товары покупают вместе?',\n",
              " 'когда вы владелец сети гипермаркетов, ответ для вас не всегда очевиден, но одно тактическое улучшение в расстановке товаров может принести хорошую прибыль.',\n",
              " 'то же касается интернет-магазинов, где задача еще интереснее — за каким товаром покупатель вернётся в следующий раз?',\n",
              " 'по непонятным мне причинам, поиск правил — самая хреново продуманная категория среди всех методов обучения.',\n",
              " 'классические способы заключаются в тупом переборе пар всех купленных товаров с помощью деревьев или множеств.',\n",
              " 'сами алгоритмы работают наполовину — могут искать закономерности, но не умеют обобщать или воспроизводить их на новых примерах.',\n",
              " 'в реальности каждый крупный ритейлер пилит свой велосипед, и никаких особых прорывов в этой области я не встречал.',\n",
              " 'максимальный уровень технологий здесь — запилить систему рекомендаций, как в пункте выше.',\n",
              " 'хотя может я просто далёк от этой области, расскажите в комментах, кто шарит?часть 2. обучение с подкреплением«брось робота в лабиринт и пусть ищет выход»\\n\\nсегодня используют для:\\n\\nсамоуправляемых автомобилей\\nроботов пылесосов\\nигр\\nавтоматической торговли\\nуправления ресурсами предприятий\\nпопулярные алгоритмы: q-learning, sarsa, dqn, a3c, генетический алгоритмнаконец мы дошли до вещей, которые, вроде, выглядят как настоящий искусственный интеллект.',\n",
              " 'многие авторы почему-то ставят обучение с подкреплением где-то между обучением с учителем и без, но я не понимаю чем они похожи.',\n",
              " 'названием?',\n",
              " 'обучение с подкреплением используют там, где задачей стоит не анализ данных, а выживание в реальной среде.средой может быть даже видеоигра.',\n",
              " 'роботы, играющие в марио, были популярны еще лет пять назад.',\n",
              " 'средой может быть реальный мир.',\n",
              " 'как пример — автопилот теслы, который учится не сбивать пешеходов, или роботы-пылесосы, главная задача которых — напугать вашего кота до усрачки с максимальной эффективностью.',\n",
              " 'знания об окружающем мире такому роботу могут быть полезны, но чисто для справки.',\n",
              " 'не важно сколько данных он соберёт, у него всё равно не получится предусмотреть все ситуации.',\n",
              " 'потому его цель — минимизировать ошибки, а не рассчитать все ходы.',\n",
              " 'робот учится выживать в пространстве с максимальной выгодой: собранными монетками в марио, временем поездки в тесле или количеством убитых кожаных мешков хихихих.',\n",
              " 'выживание в среде и есть идея обучения с подкреплением.',\n",
              " 'давайте бросим бедного робота в реальную жизнь, будем штрафовать его за ошибки и награждать за правильные поступки.',\n",
              " 'на людях норм работает, почему бы на и роботах не попробовать.',\n",
              " 'умные модели роботов-пылесосов и самоуправляемые автомобили обучаются именно так: им создают виртуальный город (часто на основе карт настоящих городов), населяют случайными пешеходами и отправляют учиться никого там не убивать.',\n",
              " 'когда робот начинает хорошо себя чувствовать в искусственном gta, его выпускают тестировать на реальные улицы.',\n",
              " 'запоминать сам город машине не нужно — такой подход называется model-free.',\n",
              " 'конечно, тут есть и классический model-based, но в нём нашей машине пришлось бы запоминать модель всей планеты, всех возможных ситуаций на всех перекрёстках мира.',\n",
              " 'такое просто не работает.',\n",
              " 'в обучении с подкреплением машина не запоминает каждое движение, а пытается обобщить ситуации, чтобы выходить из них с максимальной выгодой.помните новость пару лет назад, когда машина обыграла человека в го?',\n",
              " 'хотя незадолго до этого было доказано, что число комбинаций физически невозможно просчитать, ведь оно превышает количество атомов во вселенной.',\n",
              " 'то есть если в шахматах машина реально просчитывала все будущие комбинации и побеждала, с го так не прокатывало.',\n",
              " 'поэтому она просто выбирала наилучший выход из каждой ситуации и делала это достаточно точно, чтобы обыграть кожаного ублюдка.',\n",
              " 'эта идея лежит в основе алгоритма q-learning и его производных (sarsa и dqn).',\n",
              " 'буква q в названии означает слово quality, то есть робот учится поступать наиболее качественно в любой ситуации, а все ситуации он запоминает как простой марковский процесс.машина прогоняет миллионы симуляций в среде, запоминая все сложившиеся ситуации и выходы из них, которые принесли максимальное вознаграждение.',\n",
              " 'но как понять, когда у нас сложилась известная ситуация, а когда абсолютно новая?',\n",
              " 'вот самоуправляемый автомобиль стоит у перекрестка и загорается зелёный — значит можно ехать?',\n",
              " 'а если справа мчит скорая помощь с мигалками?',\n",
              " 'ответ — хрен знает, никак, магии не бывает, исследователи постоянно этим занимаются, изобретая свои костыли.',\n",
              " 'одни прописывают все ситуации руками, что позволяет им обрабатывать исключительные случаи типа проблемы вагонетки.',\n",
              " 'другие идут глубже и отдают эту работу нейросетям, пусть сами всё найдут.',\n",
              " \"так вместо q-learning'а у нас появляется deep q-network (dqn).\",\n",
              " 'reinforcement learning для простого обывателя выглядит как настоящий интеллект.',\n",
              " 'потому что ух ты, машина сама принимает решения в реальных ситуациях!',\n",
              " 'он сейчас на хайпе, быстро прёт вперёд и активно пытается в нейросети, чтобы стать еще точнее (а не стукаться о ножку стула по двадцать раз).',\n",
              " 'потому если вы любите наблюдать результаты своих трудов и хотите популярности — смело прыгайте в методы обучения с подкреплением (до чего ужасный русский термин, каждый раз передёргивает) и заводите канал на ютюбе!',\n",
              " 'даже я бы смотрел.помню, у меня в студенчестве были очень популярны генетические алгоритмы (по ссылке прикольная визуализация).',\n",
              " 'это когда мы бросаем кучу роботов в среду и заставляем их идти к цели, пока не сдохнут.',\n",
              " 'затем выбираем лучших, скрещиваем, добавляем мутации и бросаем еще раз.',\n",
              " 'через пару миллиардов лет должно получиться разумное существо.',\n",
              " 'теория эволюции в действии.',\n",
              " 'так вот, генетические алгоритмы тоже относятся к обучению с подкреплением, и у них есть важнейшая особенность, подтвержденная многолетней практикой — они нахер никому не нужны.',\n",
              " 'человечеству еще не удалось придумать задачу, где они были бы реально эффективнее других.',\n",
              " 'зато отлично заходят как студенческие эксперименты и позволяют кадрить научруков «достижениями» особо не заморачиваясь.',\n",
              " 'на ютюбе тоже зайдёт.часть 3. ансамбли«куча глупых деревьев учится исправлять ошибки друг друга»\\n\\nсегодня используют для:\\n\\nвсего, где подходят классические алгоритмы (но работают точнее)\\nпоисковые системы (★)\\nкомпьютерное зрение\\nраспознавание объектов\\nпопулярные алгоритмы: random forest, gradient boostingтеперь к настоящим взрослым методам.',\n",
              " 'ансамбли и нейросети — наши главные бойцы на пути к неминуемой сингулярности.',\n",
              " 'сегодня они дают самые точные результаты и используются всеми крупными компаниями в продакшене.',\n",
              " 'только о нейросетях трещат на каждом углу, а слова «бустинг» и «бэггинг», наверное, пугают только хипстеров с теккранча.при всей их эффективности, идея до издевательства проста.',\n",
              " 'оказывается, если взять несколько не очень эффективных методов обучения и обучить исправлять ошибки друг друга, качество такой системы будет аж сильно выше, чем каждого из методов по отдельности.причём даже лучше, когда взятые алгоритмы максимально нестабильны и сильно плавают от входных данных.',\n",
              " 'поэтому чаще берут регрессию и деревья решений, которым достаточно одной сильной аномалии в данных, чтобы поехала вся модель.',\n",
              " 'а вот байеса и k-nn не берут никогда — они хоть и тупые, но очень стабильные.ансамбль можно собрать как угодно, хоть случайно нарезать в тазик классификаторы и залить регрессией.',\n",
              " 'за точность, правда, тогда никто не ручается.',\n",
              " 'потому есть три проверенных способа делать ансамбли.стекинг обучаем несколько разных алгоритмов и передаём их результаты на вход последнему, который принимает итоговое решение.',\n",
              " 'типа как девочки сначала опрашивают всех своих подружек, чтобы принять решение встречаться с парнем или нет.ключевое слово — разных алгоритмов, ведь один и тот же алгоритм, обученный на одних и тех же данных не имеет смысла.',\n",
              " 'каких — ваше дело, разве что в качестве решающего алгоритма чаще берут регрессию.',\n",
              " 'чисто из опыта — стекинг на практике применяется редко, потому что два других метода обычно точнее.беггинг он же bootstrap aggregating.',\n",
              " 'обучаем один алгоритм много раз на случайных выборках из исходных данных.',\n",
              " 'в самом конце усредняем ответы.',\n",
              " 'данные в случайных выборках могут повторяться.',\n",
              " 'то есть из набора 1-2-3 мы можем делать выборки 2-2-3, 1-2-2, 3-1-2 и так пока не надоест.',\n",
              " 'на них мы обучаем один и тот же алгоритм несколько раз, а в конце вычисляем ответ простым голосованием.самый популярный пример беггинга — алгоритм random forest, беггинг на деревьях, который и нарисован на картинке.',\n",
              " 'когда вы открываете камеру на телефоне и видите как она очертила лица людей в кадре желтыми прямоугольниками — скорее всего это их работа.',\n",
              " 'нейросеть будет слишком медлительна в реальном времени, а беггинг идеален, ведь он может считать свои деревья параллельно на всех шейдерах видеокарты.',\n",
              " 'дикая способность параллелиться даёт беггингу преимущество даже над следующим методом, который работает точнее, но только в один поток.',\n",
              " 'хотя можно разбить на сегменты, запустить несколько... ах кого я учу, сами не маленькие.бустинг обучаем алгоритмы последовательно, каждый следующий уделяет особое внимание тем случаям, на которых ошибся предыдущий.',\n",
              " 'как в беггинге, мы делаем выборки из исходных данных, но теперь не совсем случайно.',\n",
              " 'в каждую новую выборку мы берём часть тех данных, на которых предыдущий алгоритм отработал неправильно.',\n",
              " 'то есть как бы доучиваем новый алгоритм на ошибках предыдущего.плюсы — неистовая, даже нелегальная в некоторых странах, точность классификации, которой позавидуют все бабушки у подъезда.',\n",
              " 'минусы уже названы — не параллелится.',\n",
              " 'хотя всё равно работает быстрее нейросетей, которые как гружёные камазы с песком по сравнению с шустрым бустингом.',\n",
              " 'нужен реальный пример работы бустинга — откройте яндекс и введите запрос.',\n",
              " 'слышите, как матрикснет грохочет деревьями и ранжирует вам результаты?',\n",
              " 'вот это как раз оно, яндекс сейчас весь на бустинге.',\n",
              " 'про google не знаю.',\n",
              " 'сегодня есть три популярных метода бустинга, отличия которых хорошо донесены в статье catboost vs. lightgbm vs. xgboostчасть 4. нейросети и глубокое обучение«у нас есть сеть из тысячи слоёв, десятки видеокарт, но мы всё еще не придумали где это может быть полезно.',\n",
              " 'пусть рисует котиков!»\\n\\nсегодня используют для:\\n\\nвместо всех вышеперечисленных алгоритмов вообще\\nопределение объектов на фото и видео\\nраспознавание и синтез речи\\nобработка изображений, перенос стиля\\nмашинный перевод\\nпопулярные архитектуры: перцептрон, свёрточные сети (cnn), рекуррентные сети (rnn), автоэнкодерыесли вам хоть раз не пытались объяснить нейросеть на примере якобы работы мозга, расскажите, как вам удалось спрятаться?',\n",
              " 'я буду избегать этих аналогий и объясню как нравится мне.',\n",
              " 'любая нейросеть — это набор нейронов и связей между ними.',\n",
              " 'нейрон лучше всего представлять просто как функцию с кучей входов и одним выходом.',\n",
              " 'задача нейрона — взять числа со своих входов, выполнить над ними функцию и отдать результат на выход.',\n",
              " 'простой пример полезного нейрона: просуммировать все цифры со входов, и если их сумма больше n — выдать на выход единицу, иначе — ноль.',\n",
              " 'связи — это каналы, через которые нейроны шлют друг другу циферки.',\n",
              " 'у каждой связи есть свой вес — её единственный параметр, который можно условно представить как прочность связи.',\n",
              " 'когда через связь с весом 0.5 проходит число 10, оно превращается в 5. сам нейрон не разбирается, что к нему пришло и суммирует всё подряд — вот веса и нужны, чтобы управлять на какие входы нейрон должен реагировать, а на какие нет.чтобы сеть не превратилась в анархию, нейроны решили связывать не как захочется, а по слоям.',\n",
              " 'внутри одного слоя нейроны никак не связаны, но соединены с нейронами следующего и предыдущего слоя.',\n",
              " 'данные в такой сети идут строго в одном направлении — от входов первого слоя к выходам последнего.',\n",
              " 'если нафигачить достаточное количество слоёв и правильно расставить веса в такой сети, получается следующее — подав на вход, скажем, изображение написанной от руки цифры 4, чёрные пиксели активируют связанные с ними нейроны, те активируют следующие слои, и так далее и далее, пока в итоге не загорится самый выход, отвечающий за четвёрку.',\n",
              " 'результат достигнут.в реальном программировании, естественно, никаких нейронов и связей не пишут, всё представляют матрицами и считают матричными произведениями, потому что нужна скорость.',\n",
              " 'у меня есть два любимых видео, в которых весь описанный мной процесс наглядно объяснён на примере распознавания рукописных цифр.',\n",
              " 'посмотрите, если хотите разобраться.такая сеть, где несколько слоёв и между ними связаны все нейроны, называется перцептроном (mlp) и считается самой простой архитектурой для новичков.',\n",
              " 'в боевых задачах лично я никогда её не встречал.',\n",
              " 'когда мы построили сеть, наша задача правильно расставить веса, чтобы нейроны реагировали на нужные сигналы.',\n",
              " 'тут нужно вспомнить, что у нас же есть данные — примеры «входов» и правильных «выходов».',\n",
              " 'будем показывать нейросети рисунок той же цифры 4 и говорить «подстрой свои веса так, чтобы на твоём выходе при таком входе всегда загоралась четвёрка».',\n",
              " 'сначала все веса просто расставлены случайно, мы показываем сети цифру, она выдаёт какой-то случайный ответ (весов-то нет), а мы сравниваем, насколько результат отличается от нужного нам.',\n",
              " 'затем идём по сети в обратном направлении, от выходов ко входам, и говорим каждому нейрону — так, ты вот тут зачем-то активировался, из-за тебя всё пошло не так, давай ты будешь чуть меньше реагировать на вот эту связь и чуть больше на вон ту, ок?',\n",
              " 'через тысяч сто таких циклов «прогнали-проверили-наказали» есть надежда, что веса в сети откорректируются так, как мы хотели.',\n",
              " 'научно этот подход называется backpropagation или «метод обратного распространения ошибки».',\n",
              " 'забавно то, что чтобы открыть этот метод понадобилось двадцать лет.',\n",
              " 'до него нейросети обучали как могли.',\n",
              " 'второй мой любимый видос более подробно объясняет весь процесс, но всё так же просто, на пальцах.',\n",
              " 'хорошо обученная нейросеть могла притворяться любым алгоритмом из этой статьи, а зачастую даже работать точнее.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yahyv942n9Xa",
        "outputId": "fd86acb1-3cfe-4842-b6b3-327f1a33b7db"
      },
      "source": [
        "word_tokens[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['цель', 'машинного', 'обучения', '—', 'предсказать']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BceOVEXoH7B"
      },
      "source": [
        "import pymorphy2\n",
        "\n",
        "lemmer = pymorphy2.MorphAnalyzer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2sfjMPOI1NQ"
      },
      "source": [
        "# from nltk.stem.wordnet import WordNetLemmatizer\n",
        "\n",
        "# eng_lemmer = WordNetLemmatizer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "67kTveWyJPJK",
        "outputId": "bfb662bf-a45e-4398-f948-7c071074094a"
      },
      "source": [
        "# eng_lemmer.lemmatize('going')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'going'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPNXz4Kfn_3n"
      },
      "source": [
        "def LemTokens(tokens):\n",
        "    return [lemmer.parse(token)[0].normal_form for token in tokens]\n",
        "    # return [eng_lemmer.lemmatize(token) for token in tokens]\n",
        "    \n",
        "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
        "\n",
        "def LemNormalize(text):\n",
        "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLiNxI4-oyGo"
      },
      "source": [
        "import re \n",
        "\n",
        "# Тут нужно менять!\n",
        "GREETING_INPUTS = (\"привет\", \"здравствуйте\", \"здорово\", \"чо каво\", \"хай\", \"салют\", \"хаюшки\", \"сап\")\n",
        "GREETING_RESPONSES = [\"привет\", \"хай\", \"*подмигнул*\", \"здравствуй\", \"рад общению с тобой\", \"приветствую\"]\n",
        "\n",
        "def greeting(sentence):\n",
        "    sentence = re.sub('[^А-Яа-яё ]', '', sentence)\n",
        "    #sentence = re.sub('[^A-Za-z ]', '', sentence)\n",
        "    for word in sentence.split():\n",
        "        if word.lower() in GREETING_INPUTS:\n",
        "            return random.choice(GREETING_RESPONSES)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcCVEtzopZS0"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Kf3-Rx5peRP"
      },
      "source": [
        "def response(user_response):\n",
        "    robo_response=''\n",
        "    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words=stopwords.words(\"russian\"))\n",
        "    # TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words=\"english\")\n",
        "    tfidf = TfidfVec.fit_transform(sent_tokens)\n",
        "    vals = cosine_similarity(tfidf[-1], tfidf)\n",
        "    idx=vals.argsort()[0][-2]\n",
        "    flat = vals.flatten()\n",
        "    flat.sort()\n",
        "    req_tfidf = flat[-2]\n",
        "    if(req_tfidf==0):\n",
        "        robo_response=robo_response+\"Извините, но я не понимаю вас!\" # ТУТ можно менять :) \n",
        "        return robo_response\n",
        "    else:\n",
        "        robo_response = robo_response+sent_tokens[idx]\n",
        "        return robo_response"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UU2whSa7prjz",
        "outputId": "e2fcb01e-edd8-4666-a85f-b18654d512d2"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "flag=True\n",
        "\n",
        "# Тут тоже нужно менять!\n",
        "print(\"Робот: Меня зовут Зак. Я буду отвечать на ваши вопросы о Машинном обучении. Если вы захотите прекратить общение, напишите Пока!\")\n",
        "while(flag==True):\n",
        "    user_response = input()\n",
        "    user_response=user_response.lower()\n",
        "    if(user_response!='пока'):\n",
        "        if(user_response in ['спасибо', 'благодарю']): # И тут меняйте :)\n",
        "            flag=False\n",
        "            print(\"Робот: Рад был помочь ;)\") # Меняйте :) \n",
        "        else:\n",
        "            if(greeting(user_response)!=None):\n",
        "                print(\"Робот: \"+greeting(user_response))\n",
        "            else:\n",
        "                sent_tokens.append(user_response)\n",
        "                word_tokens=word_tokens+nltk.word_tokenize(user_response)\n",
        "                final_words=list(set(word_tokens))\n",
        "                print(\"Робот: \",end=\"\")\n",
        "                print(response(user_response))\n",
        "                sent_tokens.remove(user_response)\n",
        "    else:\n",
        "        flag=False\n",
        "        print(\"Робот: До свидания! *машет-ручкой*\") # Тут тоже нужно импровизировать"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Робот: Меня зовут Зак. Я буду отвечать на твои вопросы о Чат-ботах. Если ты захочешь прекратить общение, напиши Пока!\n",
            "здорово\n",
            "Робот: рад общению с тобой\n",
            "виды машинного обучения\n",
            "Робот: важный, но не единственный.нейросети — один из видов машинного обучения.\n",
            "обучение с учителем\n",
            "Робот: либо, можно попробовать обучение без учителя.\n",
            "что ты знаешь о рекуррентных нейросетях\n",
            "Робот: про google не знаю.\n",
            "рекуррентные нейросети\n",
            "Робот: дай нейросети удочку — она сможет определять и удочку до конца жизни...\n",
            "\n",
            "рекуррентные нейросети (rnn)\n",
            "вторая по популярности архитектура на сегодняшний день.\n",
            "популярные архитектуры\n",
            "Робот: популярный, но есть и другие, не хуже.глубокое обучение — архитектура нейросетей, один из подходов к их построению и обучению.\n",
            "нейросети и глубокое обучение\n",
            "Робот: отличие глубокого обучения от классических нейросетей было в новых методах обучения, которые справлялись с большими размерами сетей.\n",
            "что такое бустинг\n",
            "Робот: вот это как раз оно, яндекс сейчас весь на бустинге.\n",
            "пример беггинга\n",
            "Робот: на них мы обучаем один и тот же алгоритм несколько раз, а в конце вычисляем ответ простым голосованием.самый популярный пример беггинга — алгоритм random forest, беггинг на деревьях, который и нарисован на картинке.\n",
            "благодарю\n",
            "Робот: Пожалуйста ;)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pT0iDnUiHa3n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "2ba57a47-8f0b-4402-a64e-4488a37c0367"
      },
      "source": [
        "Rasa\n",
        "\n",
        "sklearn\n",
        "tensorflow\n",
        "torch\n",
        "transformers\n",
        "mystem, pymorphy2, spacy\n",
        "gensim"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f65a1eba422d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mRasa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Rasa' is not defined"
          ]
        }
      ]
    }
  ]
}